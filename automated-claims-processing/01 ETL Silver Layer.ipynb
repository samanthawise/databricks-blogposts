{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069fb7cf-8c99-4b7c-9df1-d9e262c98fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer\n",
    "- Conversation of m4a files to mp3 files\n",
    "- Calculating audio duration in seconds\n",
    "- Generating transcripts using [OpenAI Whisper](https://openai.com/index/whisper/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c6de7b-4322-4d7e-a1aa-777981e9ee68",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Dependencies and Restart Python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pydub mutagen openai-whisper numpy>=1.24\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21fbef5f-8d95-4719-9119-e7d696ef61eb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Initial Resources for Notebook Execution"
    }
   },
   "outputs": [],
   "source": [
    "%run \"./resources/init\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65dfc242-a7ad-4b30-aa69-03a646bc360d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convert Files to MP3 and Save to New Volume"
    }
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "file_reference_df = spark.table(f\"{CATALOG}.{SCHEMA}.recordings_file_reference_bronze\")\n",
    "\n",
    "mp3_path = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/mp3_audio_recordings/\"\n",
    "if not dbutils.fs.mkdirs(mp3_path):\n",
    "    dbutils.fs.mkdirs(mp3_path)\n",
    "\n",
    "    # Convert each file to mp3 and save to the new volume\n",
    "    for row in file_reference_df.collect():\n",
    "        file_path = row['file_path']\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        new_file_path = os.path.join(mp3_path, os.path.basename(file_path).replace(os.path.splitext(file_path)[1], \".mp3\"))\n",
    "        audio.export(new_file_path, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd64d4c3-be1c-4ede-b9a4-096c573aad3b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create DataFrame with MP3 Audio Durations"
    }
   },
   "outputs": [],
   "source": [
    "from mutagen.mp3 import MP3\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "mp3_file_reference_df = spark.createDataFrame(\n",
    "    dbutils.fs.ls(f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}/mp3_audio_recordings\")\n",
    ").withColumn(\"file_path\", F.expr(\"substring(path, 6, length(path))\"))\n",
    "\n",
    "def get_audio_duration(file_path):\n",
    "    audio = MP3(file_path)\n",
    "    return audio.info.length\n",
    "\n",
    "get_audio_duration_udf = F.udf(get_audio_duration, FloatType())\n",
    "\n",
    "mp3_file_reference_df = mp3_file_reference_df.withColumn(\"audio_duration\", F.round(get_audio_duration_udf(\"file_path\"), 0))\n",
    "\n",
    "display(mp3_file_reference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5416e38-cce5-40a5-b4ca-36b6c48ea8a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Whisper Model and Print Status"
    }
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Load Whisper model (choose \"small\" for CPU, \"medium\" or \"large\" for GPU)\n",
    "model = whisper.load_model(\"small\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f174cbfe-f13c-475f-abfb-5a70f00a4e4b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transcribe Audio with Whisper Model"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path: str, model: whisper.Whisper) -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio using Whisper model.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "        model (whisper.Whisper): Whisper model instance.\n",
    "\n",
    "    Returns:\n",
    "        str: Transcribed text from the audio file.\n",
    "    \"\"\"\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8f66114-0ee3-453e-9678-6ed6be1165ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Transcribe Audio Files to Text with Spark_UDF"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "transcribe_udf = udf(lambda file_path: transcribe_audio(file_path, model), StringType())\n",
    "\n",
    "transcriptions_df = mp3_file_reference_df.withColumn(\"transcription\", transcribe_udf(\"file_path\")) \\\n",
    "                                         .select(\"path\", \"modificationTime\", \"file_path\", \"transcription\", \"audio_duration\")\n",
    "\n",
    "display(transcriptions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f75e6e4a-51e4-4d3a-a9c6-f86754f92781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# existing_transcriptions_df = spark.table(f\"{CATALOG}.{SCHEMA}.simulated_transcriptions\")\n",
    "\n",
    "# combined_transcriptions_df = existing_transcriptions_df.unionByName(transcriptions_df)\n",
    "\n",
    "# display(combined_transcriptions_df)\n",
    "\n",
    "# combined_transcriptions_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(f\"{CATALOG}.{SCHEMA}.transcriptions_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9a448c-06ee-411a-b346-d8aa01785479",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Combine and Save Transcriptions Data in Silver Table"
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(f\"{CATALOG}.{SCHEMA}.transcriptions_silver\"):\n",
    "    transcriptions_silver_df = spark.table(f\"{CATALOG}.{SCHEMA}.transcriptions_silver\")\n",
    "    combined_transcriptions_df = transcriptions_silver_df.unionByName(transcriptions_df).dropDuplicates()\n",
    "else:\n",
    "    combined_transcriptions_df = transcriptions_df.dropDuplicates()\n",
    "\n",
    "combined_transcriptions_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(f\"{CATALOG}.{SCHEMA}.transcriptions_silver\")\n",
    "\n",
    "display(combined_transcriptions_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01 ETL Silver Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
